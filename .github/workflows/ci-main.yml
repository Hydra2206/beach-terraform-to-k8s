name: CI Main - Apply + Build + Deploy

on:
  workflow_dispatch: {}
  push:
    branches:
      - main

permissions:
  contents: read
  id-token: write

jobs:
  terraform-apply:
    runs-on: ubuntu-latest
    outputs:
      kubeconfig: ${{ steps.write-kubeconfig.outputs.kubeconfig-path }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.0

      - name: Configure AWS credentials via OIDC
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Show runner path (debug)
        run: |
          echo "Working dir: $(pwd)"
          ls -la

      - name: Fetch Terraform vars from AWS Secrets Manager
        id: fetch_secret
        run: |
          echo "Retrieving secret from Secrets Manager..."
          # get secret string (plain JSON). will fail the step if it cannot retrieve.
          SECRET_JSON=$(aws secretsmanager get-secret-value --secret-id "${{ secrets.AWS_TF_VARS_SECRET_ARN }}" --query SecretString --output text)
          if [ -z "$SECRET_JSON" ]; then
            echo "::error ::Failed to read secret or secret is empty"
            exit 1
          fi
          # mask secret to avoid leaking in logs (best-effort)
          echo "::add-mask::$SECRET_JSON"
          # write JSON into terraform folder as terraform.tfvars.json so Terraform auto-loads it
          mkdir -p ./terraform
          echo "$SECRET_JSON" > ./terraform/terraform.tfvars.json
          echo "Wrote terraform/terraform.tfvars.json (not printed here for security)"

      - name: Terraform Init
        working-directory: ./terraform
        run: terraform init -input=false

      - name: Terraform Apply (auto-approve)
        working-directory: ./terraform
        run: |
          # Try applying the exact plan. Capture exit code so we can continue and set output.
          if terraform apply -auto-approve; then
            echo "apply_status=success" >> $GITHUB_OUTPUT
          else
            echo "apply_status=failure" >> $GITHUB_OUTPUT
          fi

      - name: Output kubeconfig to file
        id: write-kubeconfig
        run: |
          mkdir -p $GITHUB_WORKSPACE/.kube
          # assumes your terraform outputs cluster_name and cluster_region
          aws eks update-kubeconfig --name $(terraform output -raw cluster_name) --region $(terraform output -raw cluster_region) --kubeconfig $GITHUB_WORKSPACE/.kube/config
          echo "::set-output name=kubeconfig-path::$GITHUB_WORKSPACE/.kube/config"

  build-and-deploy:
    needs: terraform-apply
    runs-on: ubuntu-latest
    environment: production
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Configure AWS credentials to push to ECR
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Login to ECR
        id: ecr-login
        uses: aws-actions/amazon-ecr-login@v1

      - name: Build, tag, and push Docker image
        uses: docker/build-push-action@v4
        with:
          context: ./app
          push: true
          tags: ${{ steps.ecr-login.outputs.registry }}/${{ secrets.ECR_REPOSITORY }}:${{ github.sha }}

      - name: Set KUBECONFIG
        run: |
          mkdir -p $HOME/.kube
          # copy kubeconfig created by previous job
          cp ${{ needs.terraform-apply.outputs.kubeconfig }} $HOME/.kube/config
          export KUBECONFIG=$HOME/.kube/config
        shell: bash

      - name: Deploy to EKS (kubectl apply)
        run: |
          # Replace image reference in deployment manifest or use `kubectl set image`
          sed -i "s|IMAGE_PLACEHOLDER|${{ steps.ecr-login.outputs.registry }}/${{ secrets.ECR_REPOSITORY }}:${{ github.sha }}|g" ./app/k8s/deployment.yaml
          kubectl apply -f ./app/k8s

  destroy-on-failure:
    name: Terraform Destroy (runs only if terraform apply failed)
    needs: terraform-apply
    runs-on: ubuntu-latest
    if: needs.terraform-apply.outputs.apply_status == 'failure'
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Terraform
        uses: hashicorp/setup-terraform@v2
        with:
          terraform_version: 1.5.0

      - name: Configure AWS credentials via OIDC (for destroy)
        uses: aws-actions/configure-aws-credentials@v2
        with:
          role-to-assume: ${{ secrets.AWS_ROLE_TO_ASSUME_TERRAFORM }}
          aws-region: ${{ secrets.AWS_REGION }}

      - name: Debug - List terraform dir (optional)
        run: |
          echo "PWD: $(pwd)"
          ls -la ${{ env.TERRAFORM_DIR }} || true

      - name: Terraform init (for destroy)
        working-directory: ${{ env.TERRAFORM_DIR }}
        run: terraform init -input=false

      - name: Terraform refresh state (best-effort)
        working-directory: ${{ env.TERRAFORM_DIR }}
        run: terraform refresh -input=false || true

      - name: Terraform Destroy (cleanup)
        working-directory: ${{ env.TERRAFORM_DIR }}
        run: |
          echo "Terraform apply failed; attempting terraform destroy to clean up resources..."
          # Attempt to destroy whatever terraform state knows about.
          terraform destroy -auto-approve || {
            echo "terraform destroy failed. Investigate manual cleanup."
            exit 1
          }
